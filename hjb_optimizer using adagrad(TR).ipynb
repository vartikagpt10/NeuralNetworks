{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"hjb_optimizer using adagrad(TR).ipynb","provenance":[{"file_id":"1vomalPkKhP2aec3Rtl8j6AsGYZTWjeVi","timestamp":1591950407238}]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"KEJWe4Zhc4A-","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras import layers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tpOykB05c4BC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":101},"executionInfo":{"status":"ok","timestamp":1591964216367,"user_tz":-330,"elapsed":10726,"user":{"displayName":"Vartika","photoUrl":"https://lh5.googleusercontent.com/-VuAwyKZqoLI/AAAAAAAAAAI/AAAAAAAAKL4/4NHvQFffNOs/s64/photo.jpg","userId":"03459294907105822524"}},"outputId":"ca6d1d67-5cfe-4382-aada-55340adf2b1b"},"source":["batch_size = 64\n","shuffle_buffer_size = 100\n","num_classes = 10\n","epochs = 6\n","\n","# input image dimensions\n","img_rows, img_cols = 28, 28\n","\n","# the data, split between train and test sets\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n","x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n","input_shape = (img_rows, img_cols, 1)\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# convert class vectors to binary class matrices\n","y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n","y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n","\n","train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n","train_ds = train_ds.shuffle(shuffle_buffer_size).batch(batch_size)\n","test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n","test_ds = test_ds.batch(batch_size)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","x_train shape: (60000, 28, 28, 1)\n","60000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vL9kcLbjc4BH","colab_type":"code","colab":{}},"source":["model = Sequential([\n","  layers.Flatten(input_shape=(28, 28)),#input image dimensions\n","  layers.Dense(128, activation='relu'),\n","  layers.Dropout(0.2),\n","  layers.Dense(10)\n","])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k1nf7Ft8c4BO","colab_type":"code","colab":{}},"source":["def mse_grad(model, inputs, targets):\n","    with tf.GradientTape() as tape:\n","        loss_value = tf.keras.losses.mean_squared_error(y_true=targets, y_pred=model(inputs, training=True))\n","    return tape.gradient(loss_value, model.trainable_variables)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rbUOFBUget7U","colab_type":"text"},"source":["##HJB-AdaGrad Optimization"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"RGlMuSzyc4BR","colab_type":"code","colab":{}},"source":["def hjb_optimize(model, train_ds, test_ds, r=100., epochs=6, metric=tf.keras.metrics.Accuracy):\n","    train_loss_results = []\n","    train_accuracy_results = []\n","\n","    for epoch in range(epochs):\n","        epoch_loss_avg = tf.keras.metrics.Mean()\n","        epoch_accuracy = metric()\n","\n","        for x, y in train_ds:\n","            grads = mse_grad(model, x, y)\n","            grad_norm_value = 0.\n","            for g in grads:\n","                grad_norm_value = tf.sqrt(grad_norm_value**2 + tf.norm(g)**2)\n","            loss_value = model.loss(y_true=y, y_pred=model(x, training=True))\n","            for g in grads:\n","                g *= tf.sqrt(2*loss_value)\n","                g /= grad_norm_value\n","                g /= tf.sqrt(r)\n","            (model.optimizer).apply_gradients(zip(grads, model.trainable_variables))\n","            # print(\"Step: {},         Loss: {}\".format(optimizer.iterations.numpy(), loss_value))\n","\n","            # Track progress\n","            epoch_loss_avg.update_state(loss_value)\n","            epoch_accuracy.update_state(y, model(x, training=True))\n","\n","        # End epoch\n","        train_loss_results.append(epoch_loss_avg.result())\n","        train_accuracy_results.append(epoch_accuracy.result())\n","\n","\n","        if epoch % 1 == 0:\n","            print(\"Epoch {:02d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n","                                                                        epoch_loss_avg.result(),\n","                                                                        epoch_accuracy.result()))\n","\n","    test_accuracy = metric()\n","\n","    for x, y in test_ds:\n","        test_accuracy.update_state(y, model(x, training=False))\n","\n","    print(\"Test set accuracy: {:.3%}\".format(test_accuracy.result()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fOgT8ymq-Rrf","colab_type":"code","colab":{}},"source":["model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=tf.keras.optimizers.Adagrad(), metrics=['accuracy'])\n","hjb_optimize(model, train_ds, test_ds, r=100., epochs=epochs, metric=tf.keras.metrics.Accuracy)"],"execution_count":null,"outputs":[]}]}